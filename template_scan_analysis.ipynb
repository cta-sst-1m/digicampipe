{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Scan Analysis\n",
    "\n",
    "This notebook is the 2nd part of the template scan analysis. Its input are the output files of the `template_scan_analysis.sh` shell script, which is simply a little script calling the `digicam-template` command on a defined set of raw-data files for you, so everybody can be sure to get the same results.\n",
    "\n",
    "Let us quickly check if the 3 files are really here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls template_scan_dac_*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we import all the libs we are going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "from matplotlib import colors\n",
    "from glob import glob\n",
    "from scipy import interp, interpolate\n",
    "from scipy.interpolate import BSpline, CubicSpline\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the histograms into memory, so we have quick and easy access, also we define a few global variables like `x_bin_center`, `y_bin_center` and `extent`, for plotting and analysis of the histograms. We store the histograms in the `H` dict using the file names as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob('template_scan_dac_*.h5'))\n",
    "H = {}\n",
    "for path in paths:\n",
    "    with h5py.File(path) as f:\n",
    "        dset = f['adc_count_histo']\n",
    "        H[path] = dset[...]\n",
    "        extent = dset.attrs['extent']\n",
    "\n",
    "        x_bin_edges = np.linspace(*extent[:2], dset.shape[1]+1)\n",
    "        y_bin_edges = np.linspace(*extent[2:], dset.shape[2]+1)\n",
    "\n",
    "        x_bin_center = (x_bin_edges[1:] + x_bin_edges[:-1]) / 2\n",
    "        y_bin_center = (y_bin_edges[1:] + y_bin_edges[:-1]) / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you a feeling what we are working with in the next few cells, let us plot just one example histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_id = 133\n",
    "for h in H.values():\n",
    "    plt.imshow(\n",
    "        h[pixel_id].T,\n",
    "        origin='bottom',\n",
    "        extent=extent,\n",
    "        norm=colors.LogNorm()\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.gca().set_aspect('auto')\n",
    "    plt.xlabel('time around 50% max height [ns]')\n",
    "    plt.ylabel('normalized amplitude')\n",
    "    plt.title('example 2d histogram from pixel {}'.format(pixel_id))\n",
    "    break\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function `analyse_2d_histo_for_pixel` takes one of these histograms we have just seen, calculates the profile (think TProfile, if you are a ROOT user) and fits a cubic spline to the profile (where we think we know it well enough).\n",
    "\n",
    "*Developer remark:*\n",
    "This function clearly does more than one thing, hence the general name \"analyse\". \n",
    "I think, \"mode\", \"mean\", \"std\" could also be methods of a Histogram2D class, then this function basically boils down to calculating the spline, which will look much cleaner.\n",
    "\n",
    "Also you see this function looks again into the globals: `y_bin_center`and `x_bin_center`, this is also bad, as you see below, when I analyze the combined histogram of all 1296 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_2d_histo_for_pixel(histogram_2d):\n",
    "    _h = histogram_2d\n",
    "    N = _h.sum(axis=-1)\n",
    "    mode = y_bin_center[_h.argmax(axis=-1)]\n",
    "    mean = (_h * y_bin_center[None, :]).sum(axis=-1)  / N\n",
    "    squared_sum = (y_bin_center[None, :] - mean[:, None])**2\n",
    "    std = np.sqrt((_h * squared_sum).sum(axis=-1) / (N-1))\n",
    "\n",
    "    average_std = np.nanmean(std)\n",
    "\n",
    "    # For the spline we only use those bins, where we have \"enough\"\n",
    "    # statistics. I define here \"enough\" as 100 entries\n",
    "    G = N >= 100\n",
    "    _x = x_bin_center[G]\n",
    "    _y = mean[G]\n",
    "    spl = CubicSpline(_x, _y)\n",
    "    return {\n",
    "        'mode': mode,\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'N': N,\n",
    "        'spline': spl,\n",
    "        'enough_entries': G,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive function below was useful in the beginning to explore the datasets and see what the problems might be.\n",
    "It grew over time, and you see it is quite long. It does however not perform any analysis task. It is just plotting results, so you can ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def plot(pid=(0, 1295)):\n",
    "    N = len(H)\n",
    "    fig, ax = plt.subplots(N+1, figsize=(12, 12), sharex=True)\n",
    "    splines = []\n",
    "    for ax_id, (path, h) in enumerate(H.items()):\n",
    "        result = analyse_2d_histo_for_pixel(h[pid])\n",
    "        splines.append((\n",
    "            result['spline'], \n",
    "            np.nanmean(result['std'])\n",
    "        ))\n",
    "        G = result['enough_entries']\n",
    "\n",
    "        img = ax[ax_id].imshow(\n",
    "            h[pid].T,\n",
    "            origin='bottom',\n",
    "            extent=extent,\n",
    "            norm=colors.LogNorm()\n",
    "        )\n",
    "        plt.colorbar(img, ax=ax[ax_id])\n",
    "\n",
    "        ax[ax_id].errorbar(\n",
    "            x=x_bin_center[G], \n",
    "            y=result['mean'][G], \n",
    "            yerr=result['std'][G],\n",
    "            fmt='.', \n",
    "            color='red'\n",
    "        )\n",
    "        __x = np.linspace(x_bin_center.min(), x_bin_center.max(), 1000)\n",
    "        ax[ax_id].plot(__x, result['spline'](__x), '-', color='magenta', lw=1)\n",
    "\n",
    "        ax[ax_id].set_aspect('auto')\n",
    "        ax[ax_id].set_ylabel('normalized amplitude')\n",
    "        ax[ax_id].set_title('Path:{}'.format(path))\n",
    "        ax[ax_id].grid()\n",
    "\n",
    "    for spl, average_std in splines:\n",
    "        __x = np.linspace(x_bin_center.min(), x_bin_center.max(), 1000)\n",
    "        ax[-1].plot(__x, spl(__x), '-', label='avg std: {:.2f}'.format(average_std))\n",
    "    ax[-1].grid()\n",
    "    ax[-1].legend()\n",
    "        \n",
    "    plt.suptitle('Pixel: {}'.format(pid))\n",
    "    plt.xlabel('time around 50% max height [ns]')\n",
    "    plt.tight_layout()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below tries to find the \"best\" spline for every pixel. You can see above that depending on the DAC setting, the pixel can saturate, which is visible here as a longer but flatter curve.\n",
    "\n",
    "Other pixel look into LEDs which are comparatively dim, i.e. at low DAC settings these pixel might see no light at all, while at the highest DAC setting they see enough light to produce a nicely defined template curve.\n",
    "\n",
    "In order to find the \"best\" (non-saturating) template I say:\n",
    " * if all profiles have very low std deviations, then take the highest template.\n",
    " * if not all profiles have low std deviations, then take the one with the smallest errors.\n",
    " \n",
    "I think this method is not perfect, but at the moment, I have no better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splines = []\n",
    "\n",
    "for pid in trange(1296):\n",
    "    sub_splines = {}\n",
    "    for path, h in H.items():\n",
    "        result = analyse_2d_histo_for_pixel(h[pid])\n",
    "        max_amplitude = result['spline'](np.linspace(0, 20, 50)).max()\n",
    "        sub_splines[(max_amplitude, np.nanmean(result['std']))] = result['spline']\n",
    "    \n",
    "    keys = list(sub_splines.keys())\n",
    "    average_stds = np.array([k[-1] for k in keys])\n",
    "    max_amplitudes = np.array([k[0] for k in keys])\n",
    "    if (average_stds < 0.05).all():\n",
    "        splines.append(sub_splines[keys[np.argmax(max_amplitudes)]])\n",
    "    else:\n",
    "        splines.append(sub_splines[keys[np.argmin(average_stds)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below simply plots the splines for all 1296 pixels into one plot, to understand if we really need one template per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "_x = np.linspace(x_bin_center.min(), x_bin_center.max(), 1000)\n",
    "\n",
    "for spl in splines:\n",
    "    x.append(_x)\n",
    "    y.append(spl(_x))\n",
    "    \n",
    "x = np.concatenate(x)\n",
    "y = np.concatenate(y)\n",
    "plt.figure(figsize=(18, 12))\n",
    "histogram_2d, xe, ye, _ = plt.hist2d(\n",
    "    x, \n",
    "    y, \n",
    "    bins=(501, 501), \n",
    "    range=[extent[:2], extent[2:]],\n",
    "    norm=colors.LogNorm()\n",
    ")\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "None\n",
    "\n",
    "_h = histogram_2d\n",
    "xc = (xe[1:] + xe[:-1]) / 2\n",
    "yc = (ye[1:] + ye[:-1]) / 2\n",
    "N = _h.sum(axis=-1)\n",
    "mode = yc[_h.argmax(axis=-1)]\n",
    "mean = (_h * yc[None, :]).sum(axis=-1)  / N\n",
    "squared_sum = (yc[None, :] - mean[:, None])**2\n",
    "std = np.sqrt((_h * squared_sum).sum(axis=-1) / (N-1))\n",
    "\n",
    "average_std = np.nanmean(std)\n",
    "\n",
    "# For the spline we only use those bins, where we have \"enough\"\n",
    "# statistics. I define here \"enough\" as 100 entries\n",
    "G = N >= 100\n",
    "_x = xc[G]\n",
    "_y = mean[G]\n",
    "spl = CubicSpline(_x, _y)\n",
    "\n",
    "plt.errorbar(\n",
    "    x=xc,\n",
    "    y=mean,\n",
    "    yerr=std / np.sqrt(1296),\n",
    "    fmt='.',\n",
    "    color='red'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the cell below, we can see how the `pulse_SST-1M_pixel_0.dat` looks in comparison to the average template we got from 1296 different pixels. I find it remarkably similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digicampipe.utils.utils import get_pulse_shape\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(xc, mean, label='mean of 1296 templates')\n",
    "plt.plot(\n",
    "    xc,\n",
    "    get_pulse_shape(xc, -7.5, np.nanmax(mean), 0),\n",
    "    label='pulse_SST-1M_pixel_0.dat'\n",
    ")\n",
    "plt.xlabel('time around 50% max height [ns]')\n",
    "plt.ylabel('normalized amplitude')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
